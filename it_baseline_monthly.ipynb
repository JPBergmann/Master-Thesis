{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, PowerTransformer, minmax_scale, power_transform, scale, minmax_scale\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from helpers.iterative import *\n",
    "\n",
    "# Set global seed for reproducibility in numpy, torch, scikit-learn\n",
    "pl.seed_everything(42)\n",
    "# torch.manual_seed(42)\n",
    "# torch.mps.manual_seed(42)\n",
    "# torch.backends.mps.deterministic = True\n",
    "# torch.cuda.manual_seed(42)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with sample of 10 companies for architecture design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data as tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data by going to project root using pd.read_parquet\n",
    "data = pd.read_parquet(\"./DATA/Monthly/Processed/month_data_fin_tec.parquet\")\n",
    "macro = pd.read_parquet(\"./DATA/Monthly/Processed/month_data_macro_USCA.parquet\")\n",
    "with open(\"./DATA/Tickers/month_tickers_clean.txt\", \"r\") as f:\n",
    "    tickers = f.read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 281 entries, 2000-01-31 to 2023-05-31\n",
      "Columns: 41309 entries, SLF_CR to DXT_others_cr\n",
      "dtypes: float64(40900), int64(409)\n",
      "memory usage: 88.6 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IVEY Index</th>\n",
       "      <th>CAEICAIR Index</th>\n",
       "      <th>CACAPUTL Index</th>\n",
       "      <th>CACOUSCO Index</th>\n",
       "      <th>GCAN10YR Index</th>\n",
       "      <th>GCAN2YR Index</th>\n",
       "      <th>OEOTKLAF Index</th>\n",
       "      <th>RRCACONT Index</th>\n",
       "      <th>SPTSX Index</th>\n",
       "      <th>MXWO Index</th>\n",
       "      <th>...</th>\n",
       "      <th>CAIPYOY Index</th>\n",
       "      <th>COSYNFRM Index</th>\n",
       "      <th>IMP1YOY% Index</th>\n",
       "      <th>CAWCWGCY Index</th>\n",
       "      <th>CDGGBE10 Index</th>\n",
       "      <th>CL1 Comdty</th>\n",
       "      <th>CRB CMDT Index</th>\n",
       "      <th>EHSLMP%Y Index</th>\n",
       "      <th>OUSTUS Index</th>\n",
       "      <th>EUCBCI Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>255390</td>\n",
       "      <td>86.1</td>\n",
       "      <td>108.2</td>\n",
       "      <td>6.538</td>\n",
       "      <td>6.273</td>\n",
       "      <td>101.2716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8481.11</td>\n",
       "      <td>1338.25</td>\n",
       "      <td>...</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>27.64</td>\n",
       "      <td>225.03</td>\n",
       "      <td>2.32</td>\n",
       "      <td>86.24</td>\n",
       "      <td>90.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>150690</td>\n",
       "      <td>86.1</td>\n",
       "      <td>108.3</td>\n",
       "      <td>6.126</td>\n",
       "      <td>5.984</td>\n",
       "      <td>101.2993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9128.99</td>\n",
       "      <td>1340.58</td>\n",
       "      <td>...</td>\n",
       "      <td>5.30</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>30.43</td>\n",
       "      <td>220.68</td>\n",
       "      <td>4.49</td>\n",
       "      <td>86.45</td>\n",
       "      <td>90.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>144590</td>\n",
       "      <td>85.7</td>\n",
       "      <td>108.4</td>\n",
       "      <td>5.922</td>\n",
       "      <td>5.936</td>\n",
       "      <td>101.2977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9462.39</td>\n",
       "      <td>1431.94</td>\n",
       "      <td>...</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.4</td>\n",
       "      <td>9.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>26.90</td>\n",
       "      <td>228.01</td>\n",
       "      <td>3.59</td>\n",
       "      <td>86.87</td>\n",
       "      <td>91.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>130150</td>\n",
       "      <td>85.7</td>\n",
       "      <td>108.5</td>\n",
       "      <td>6.170</td>\n",
       "      <td>6.139</td>\n",
       "      <td>101.2694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9347.61</td>\n",
       "      <td>1370.11</td>\n",
       "      <td>...</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25.74</td>\n",
       "      <td>227.37</td>\n",
       "      <td>4.10</td>\n",
       "      <td>87.21</td>\n",
       "      <td>91.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>135980</td>\n",
       "      <td>85.7</td>\n",
       "      <td>108.5</td>\n",
       "      <td>6.031</td>\n",
       "      <td>6.195</td>\n",
       "      <td>101.2148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9251.99</td>\n",
       "      <td>1334.14</td>\n",
       "      <td>...</td>\n",
       "      <td>5.23</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>29.01</td>\n",
       "      <td>234.16</td>\n",
       "      <td>3.57</td>\n",
       "      <td>87.40</td>\n",
       "      <td>91.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31</th>\n",
       "      <td>54.7</td>\n",
       "      <td>308620</td>\n",
       "      <td>81.8</td>\n",
       "      <td>141.2</td>\n",
       "      <td>2.916</td>\n",
       "      <td>3.752</td>\n",
       "      <td>98.6910</td>\n",
       "      <td>70040.0</td>\n",
       "      <td>20767.38</td>\n",
       "      <td>2785.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.78</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.802</td>\n",
       "      <td>78.87</td>\n",
       "      <td>557.02</td>\n",
       "      <td>1.30</td>\n",
       "      <td>136.77</td>\n",
       "      <td>107.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28</th>\n",
       "      <td>50.8</td>\n",
       "      <td>158610</td>\n",
       "      <td>81.8</td>\n",
       "      <td>141.2</td>\n",
       "      <td>3.329</td>\n",
       "      <td>4.205</td>\n",
       "      <td>98.6910</td>\n",
       "      <td>66990.0</td>\n",
       "      <td>20221.19</td>\n",
       "      <td>2714.57</td>\n",
       "      <td>...</td>\n",
       "      <td>1.36</td>\n",
       "      <td>4.9</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.073</td>\n",
       "      <td>77.05</td>\n",
       "      <td>548.53</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>137.01</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31</th>\n",
       "      <td>65.2</td>\n",
       "      <td>161720</td>\n",
       "      <td>81.9</td>\n",
       "      <td>141.2</td>\n",
       "      <td>2.897</td>\n",
       "      <td>3.737</td>\n",
       "      <td>98.6910</td>\n",
       "      <td>64956.0</td>\n",
       "      <td>20099.89</td>\n",
       "      <td>2791.44</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.807</td>\n",
       "      <td>75.67</td>\n",
       "      <td>550.63</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>137.41</td>\n",
       "      <td>107.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-30</th>\n",
       "      <td>55.6</td>\n",
       "      <td>150170</td>\n",
       "      <td>81.9</td>\n",
       "      <td>141.2</td>\n",
       "      <td>2.841</td>\n",
       "      <td>3.656</td>\n",
       "      <td>98.6910</td>\n",
       "      <td>65545.0</td>\n",
       "      <td>20636.54</td>\n",
       "      <td>2835.93</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.749</td>\n",
       "      <td>76.78</td>\n",
       "      <td>547.45</td>\n",
       "      <td>-2.86</td>\n",
       "      <td>137.88</td>\n",
       "      <td>107.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-31</th>\n",
       "      <td>60.1</td>\n",
       "      <td>150170</td>\n",
       "      <td>81.9</td>\n",
       "      <td>141.2</td>\n",
       "      <td>3.187</td>\n",
       "      <td>4.218</td>\n",
       "      <td>98.6910</td>\n",
       "      <td>70010.0</td>\n",
       "      <td>19572.24</td>\n",
       "      <td>2800.56</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.33</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.842</td>\n",
       "      <td>68.09</td>\n",
       "      <td>541.45</td>\n",
       "      <td>-3.44</td>\n",
       "      <td>138.07</td>\n",
       "      <td>108.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>281 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            IVEY Index  CAEICAIR Index  CACAPUTL Index  CACOUSCO Index  \\\n",
       "2000-01-31         0.0          255390            86.1           108.2   \n",
       "2000-02-29         0.0          150690            86.1           108.3   \n",
       "2000-03-31         0.0          144590            85.7           108.4   \n",
       "2000-04-30         0.0          130150            85.7           108.5   \n",
       "2000-05-31         0.0          135980            85.7           108.5   \n",
       "...                ...             ...             ...             ...   \n",
       "2023-01-31        54.7          308620            81.8           141.2   \n",
       "2023-02-28        50.8          158610            81.8           141.2   \n",
       "2023-03-31        65.2          161720            81.9           141.2   \n",
       "2023-04-30        55.6          150170            81.9           141.2   \n",
       "2023-05-31        60.1          150170            81.9           141.2   \n",
       "\n",
       "            GCAN10YR Index  GCAN2YR Index  OEOTKLAF Index  RRCACONT Index  \\\n",
       "2000-01-31           6.538          6.273        101.2716             0.0   \n",
       "2000-02-29           6.126          5.984        101.2993             0.0   \n",
       "2000-03-31           5.922          5.936        101.2977             0.0   \n",
       "2000-04-30           6.170          6.139        101.2694             0.0   \n",
       "2000-05-31           6.031          6.195        101.2148             0.0   \n",
       "...                    ...            ...             ...             ...   \n",
       "2023-01-31           2.916          3.752         98.6910         70040.0   \n",
       "2023-02-28           3.329          4.205         98.6910         66990.0   \n",
       "2023-03-31           2.897          3.737         98.6910         64956.0   \n",
       "2023-04-30           2.841          3.656         98.6910         65545.0   \n",
       "2023-05-31           3.187          4.218         98.6910         70010.0   \n",
       "\n",
       "            SPTSX Index  MXWO Index  ...  CAIPYOY Index  COSYNFRM Index  \\\n",
       "2000-01-31      8481.11     1338.25  ...           3.74             0.9   \n",
       "2000-02-29      9128.99     1340.58  ...           5.30             0.9   \n",
       "2000-03-31      9462.39     1431.94  ...           4.97             4.4   \n",
       "2000-04-30      9347.61     1370.11  ...           4.97             4.4   \n",
       "2000-05-31      9251.99     1334.14  ...           5.23             4.4   \n",
       "...                 ...         ...  ...            ...             ...   \n",
       "2023-01-31     20767.38     2785.00  ...           4.78             4.9   \n",
       "2023-02-28     20221.19     2714.57  ...           1.36             4.9   \n",
       "2023-03-31     20099.89     2791.44  ...          -2.09             3.8   \n",
       "2023-04-30     20636.54     2835.93  ...          -3.75             3.8   \n",
       "2023-05-31     19572.24     2800.56  ...          -6.33             3.8   \n",
       "\n",
       "            IMP1YOY% Index  CAWCWGCY Index  CDGGBE10 Index  CL1 Comdty  \\\n",
       "2000-01-31             7.1             3.1           0.000       27.64   \n",
       "2000-02-29             9.3             3.1           0.000       30.43   \n",
       "2000-03-31             9.2             3.2           0.000       26.90   \n",
       "2000-04-30             6.6             3.2           0.000       25.74   \n",
       "2000-05-31             6.1             3.2           0.000       29.01   \n",
       "...                    ...             ...             ...         ...   \n",
       "2023-01-31             0.9             3.4           1.802       78.87   \n",
       "2023-02-28            -1.1             3.4           2.073       77.05   \n",
       "2023-03-31            -4.7             2.8           1.807       75.67   \n",
       "2023-04-30            -4.9             2.8           1.749       76.78   \n",
       "2023-05-31            -5.9             2.8           1.842       68.09   \n",
       "\n",
       "            CRB CMDT Index  EHSLMP%Y Index  OUSTUS Index  EUCBCI Index  \n",
       "2000-01-31          225.03            2.32         86.24          90.6  \n",
       "2000-02-29          220.68            4.49         86.45          90.9  \n",
       "2000-03-31          228.01            3.59         86.87          91.1  \n",
       "2000-04-30          227.37            4.10         87.21          91.4  \n",
       "2000-05-31          234.16            3.57         87.40          91.7  \n",
       "...                    ...             ...           ...           ...  \n",
       "2023-01-31          557.02            1.30        136.77         107.7  \n",
       "2023-02-28          548.53           -0.51        137.01         108.0  \n",
       "2023-03-31          550.63           -1.53        137.41         107.8  \n",
       "2023-04-30          547.45           -2.86        137.88         107.9  \n",
       "2023-05-31          541.45           -3.44        138.07         108.1  \n",
       "\n",
       "[281 rows x 51 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 281 entries, 2000-01-31 to 2023-05-31\n",
      "Columns: 51 entries, IVEY Index to EUCBCI Index\n",
      "dtypes: float64(41), int64(10)\n",
      "memory usage: 114.2 KB\n"
     ]
    }
   ],
   "source": [
    "macro.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any NAN or infinite values\n",
    "data.isna().sum().sum(), np.isinf(data).sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single company approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = format_tensors_it(data,\n",
    "                                                                macro, \n",
    "                                                                tickers[10],\n",
    "                                                                lookback=6, \n",
    "                                                                pred_horizon=1,\n",
    "                                                                multistep=False,\n",
    "                                                                multicolinearity_threshold=None,\n",
    "                                                                debug=False,\n",
    "                                                                start_train_at=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.min(), X_train.max(), X_val.min(), X_val.max(), X_test.min(), X_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.min(), y_train.max(), y_val.min(), y_val.max(), y_test.min(), y_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(X_train).any(), np.isnan(X_val).any(), np.isnan(X_test).any(), np.isinf(X_train).any(), np.isinf(X_val).any(), np.isinf(X_test).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(y_train).any(), np.isnan(y_val).any(), np.isnan(y_test).any(), np.isinf(y_train).any(), np.isinf(y_test).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train).float()\n",
    "X_val_tensor = torch.from_numpy(X_val).float()\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "y_val_tensor = torch.from_numpy(y_val).float()\n",
    "y_test_tensor = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor.shape, X_val_tensor.shape, X_test_tensor.shape, y_train_tensor.shape, y_val_tensor.shape, y_test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARING_RATE = 1e-4 # 1e-4 ind standard\n",
    "EPOCHS = 300\n",
    "BATCH_SIZE = 32 # Small batch size since we are using a small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See iteration of data\n",
    "for i, (X, y) in enumerate(train_loader):\n",
    "    print(X.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from torch import nn\n",
    "import lightning.pytorch as pl\n",
    "from pytorch_ranger import Ranger\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "class LSTM(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.automatic_optimization = False\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0, bidirectional=False)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        y_hat = self.forward(X)#.squeeze(1)\n",
    "        loss = nn.functional.mse_loss(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "    \n",
    "        # Ranger requires manual backward pass since it is designed/executed differently to base torch optimizers\n",
    "        optimizer = self.optimizers()\n",
    "        optimizer.zero_grad()\n",
    "        self.manual_backward(loss)\n",
    "        optimizer.step()\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        y_hat = self.forward(X).squeeze(1)\n",
    "        loss = nn.functional.mse_loss(y_hat, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Ranger(self.parameters(), lr=LEARING_RATE)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train_tensor.shape[2]\n",
    "hidden_size = input_size\n",
    "num_layers = 2\n",
    "output_size = 1 # 1 if multi_step set to false, 2 for true\n",
    "dropout = 0 #.5\n",
    "input_size, hidden_size, num_layers, output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_size=input_size, \n",
    "             hidden_size=hidden_size, \n",
    "             num_layers=num_layers, \n",
    "             output_size=output_size, \n",
    "             dropout=dropout,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first iter of train loader using next\n",
    "x_in, y_in = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in.shape, y_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, input_size=(BATCH_SIZE, X_train_tensor.shape[1], X_train_tensor.shape[2]), col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = pl.callbacks.EarlyStopping(monitor=\"val_loss\", patience=20, mode=\"min\")\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(save_top_k=1, monitor=\"val_loss\", mode=\"min\")\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", max_epochs=EPOCHS, log_every_n_steps=1, callbacks=[early_stopping, checkpoint_callback], enable_checkpointing=True, enable_progress_bar=True)\n",
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best model path: {checkpoint_callback.best_model_path}\")\n",
    "print(f\"Best model score: {checkpoint_callback.best_model_score}\")\n",
    "\n",
    "best_model = LSTM.load_from_checkpoint(checkpoint_path=checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "with torch.inference_mode():\n",
    "    y_pred = best_model(X_val_tensor.to(device)).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 score and MAPE\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_val_tensor, y_pred):.4%}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_val_tensor, y_pred):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
